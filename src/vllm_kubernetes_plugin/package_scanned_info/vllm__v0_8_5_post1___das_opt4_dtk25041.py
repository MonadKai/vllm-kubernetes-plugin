# -*- coding: utf-8 -*-
"""vllm codebase scanned information"""
# This file is automatically generated by scripts/generate_package_scanned_info.py, do not modify manually

MODULES_WITH_LOGGER = ['vllm._custom_ops', 'vllm._ipex_ops', 'vllm.adapter_commons.models', 'vllm.attention.backends.flash_attn', 'vllm.attention.backends.flashinfer', 'vllm.attention.backends.ipex_attn', 'vllm.attention.backends.rocm_flash_attn', 'vllm.attention.backends.torch_sdpa', 'vllm.attention.backends.triton_config', 'vllm.attention.backends.triton_mla', 'vllm.attention.backends.utils', 'vllm.attention.ops.flashmla', 'vllm.attention.ops.triton_decode_attention', 'vllm.attention.selector', 'vllm.benchmarks.datasets', 'vllm.compilation.backends', 'vllm.compilation.decorators', 'vllm.compilation.fix_functionalization', 'vllm.compilation.fusion', 'vllm.compilation.monitor', 'vllm.compilation.noop_elimination', 'vllm.compilation.pass_manager', 'vllm.compilation.sequence_parallelism', 'vllm.compilation.vllm_inductor_pass', 'vllm.compilation.wrapper', 'vllm.config', 'vllm.core.block.prefix_caching_block', 'vllm.core.scheduler', 'vllm.distributed', 'vllm.distributed.device_communicators.cuda_wrapper', 'vllm.distributed.device_communicators.custom_all_reduce', 'vllm.distributed.device_communicators.custom_all_reduce_utils', 'vllm.distributed.device_communicators.pynccl', 'vllm.distributed.device_communicators.pynccl_wrapper', 'vllm.distributed.device_communicators.shm_broadcast', 'vllm.distributed.device_communicators.tpu_communicator', 'vllm.distributed.kv_transfer.kv_connector.factory', 'vllm.distributed.kv_transfer.kv_connector.lmcache_connector', 'vllm.distributed.kv_transfer.kv_connector.mooncake_store_connector', 'vllm.distributed.kv_transfer.kv_connector.simple_connector', 'vllm.distributed.kv_transfer.kv_connector.utils', 'vllm.distributed.kv_transfer.kv_connector.v1.base', 'vllm.distributed.kv_transfer.kv_connector.v1.shared_storage_connector', 'vllm.distributed.kv_transfer.kv_connector_agent', 'vllm.distributed.kv_transfer.kv_lookup_buffer.mooncake_store', 'vllm.distributed.kv_transfer.kv_lookup_buffer.simple_buffer', 'vllm.distributed.kv_transfer.kv_pipe.mooncake_pipe', 'vllm.distributed.kv_transfer.kv_pipe.pynccl_pipe', 'vllm.distributed.parallel_state', 'vllm.distributed.utils', 'vllm.engine.arg_utils', 'vllm.engine.async_llm_engine', 'vllm.engine.llm_engine', 'vllm.engine.metrics', 'vllm.engine.multiprocessing.client', 'vllm.engine.multiprocessing.engine', 'vllm.engine.output_processor.multi_step', 'vllm.engine.output_processor.single_step', 'vllm.engine.protocol', 'vllm.entrypoints.api_server', 'vllm.entrypoints.chat_utils', 'vllm.entrypoints.launcher', 'vllm.entrypoints.llm', 'vllm.entrypoints.logger', 'vllm.entrypoints.openai.api_server', 'vllm.entrypoints.openai.protocol', 'vllm.entrypoints.openai.run_batch', 'vllm.entrypoints.openai.serving_chat', 'vllm.entrypoints.openai.serving_completion', 'vllm.entrypoints.openai.serving_embedding', 'vllm.entrypoints.openai.serving_engine', 'vllm.entrypoints.openai.serving_models', 'vllm.entrypoints.openai.serving_pooling', 'vllm.entrypoints.openai.serving_score', 'vllm.entrypoints.openai.serving_tokenization', 'vllm.entrypoints.openai.serving_transcription', 'vllm.entrypoints.openai.tool_parsers.abstract_tool_parser', 'vllm.entrypoints.openai.tool_parsers.granite_20b_fc_tool_parser', 'vllm.entrypoints.openai.tool_parsers.granite_tool_parser', 'vllm.entrypoints.openai.tool_parsers.hermes_tool_parser', 'vllm.entrypoints.openai.tool_parsers.internlm2_tool_parser', 'vllm.entrypoints.openai.tool_parsers.jamba_tool_parser', 'vllm.entrypoints.openai.tool_parsers.llama_tool_parser', 'vllm.entrypoints.openai.tool_parsers.mistral_tool_parser', 'vllm.entrypoints.openai.tool_parsers.phi4mini_tool_parser', 'vllm.entrypoints.openai.tool_parsers.pythonic_tool_parser', 'vllm.entrypoints.ssl', 'vllm.entrypoints.utils', 'vllm.executor.executor_base', 'vllm.executor.mp_distributed_executor', 'vllm.executor.multiproc_worker_utils', 'vllm.executor.ray_distributed_executor', 'vllm.executor.ray_utils', 'vllm.executor.uniproc_executor', 'vllm.forward_context', 'vllm.inputs.preprocess', 'vllm.logger', 'vllm.lora.models', 'vllm.lora.peft_helper', 'vllm.lora.punica_wrapper.punica_selector', 'vllm.lora.resolver', 'vllm.lora.utils', 'vllm.lora.worker_manager', 'vllm.model_executor.custom_op', 'vllm.model_executor.guided_decoding', 'vllm.model_executor.guided_decoding.guidance_logits_processors', 'vllm.model_executor.guided_decoding.outlines_logits_processors', 'vllm.model_executor.guided_decoding.xgrammar_decoding', 'vllm.model_executor.layers.fused_moe.deep_gemm_moe', 'vllm.model_executor.layers.fused_moe.fused_moe', 'vllm.model_executor.layers.fused_moe.layer', 'vllm.model_executor.layers.linear', 'vllm.model_executor.layers.quantization.awq', 'vllm.model_executor.layers.quantization.awq_marlin', 'vllm.model_executor.layers.quantization.bitblas', 'vllm.model_executor.layers.quantization.blockwise_int8', 'vllm.model_executor.layers.quantization.compressed_tensors.compressed_tensors', 'vllm.model_executor.layers.quantization.compressed_tensors.compressed_tensors_moe', 'vllm.model_executor.layers.quantization.compressed_tensors.schemes.compressed_tensors_w8a8_int8', 'vllm.model_executor.layers.quantization.compressed_tensors.schemes.compressed_tensors_wNa16', 'vllm.model_executor.layers.quantization.fbgemm_fp8', 'vllm.model_executor.layers.quantization.fp8', 'vllm.model_executor.layers.quantization.gguf', 'vllm.model_executor.layers.quantization.gptq_bitblas', 'vllm.model_executor.layers.quantization.gptq_marlin', 'vllm.model_executor.layers.quantization.gptq_marlin_24', 'vllm.model_executor.layers.quantization.hqq_marlin', 'vllm.model_executor.layers.quantization.kernels.mixed_precision.bitblas', 'vllm.model_executor.layers.quantization.kv_cache', 'vllm.model_executor.layers.quantization.marlin', 'vllm.model_executor.layers.quantization.modelopt', 'vllm.model_executor.layers.quantization.ptpc_fp8', 'vllm.model_executor.layers.quantization.qqq', 'vllm.model_executor.layers.quantization.quark.quark_moe', 'vllm.model_executor.layers.quantization.quark.schemes.quark_w8a8_int8', 'vllm.model_executor.layers.quantization.utils.fp8_utils', 'vllm.model_executor.layers.quantization.utils.fused_moe_cuda', 'vllm.model_executor.layers.quantization.utils.marlin_utils_fp8', 'vllm.model_executor.layers.rejection_sampler', 'vllm.model_executor.layers.typical_acceptance_sampler', 'vllm.model_executor.model_loader.loader', 'vllm.model_executor.model_loader.mixed_precision_utils', 'vllm.model_executor.model_loader.tensorizer', 'vllm.model_executor.model_loader.utils', 'vllm.model_executor.model_loader.weight_utils', 'vllm.model_executor.models.arctic', 'vllm.model_executor.models.bart', 'vllm.model_executor.models.chameleon', 'vllm.model_executor.models.eagle', 'vllm.model_executor.models.ernie45', 'vllm.model_executor.models.ernie45_moe', 'vllm.model_executor.models.gemma', 'vllm.model_executor.models.gemma2', 'vllm.model_executor.models.gemma3', 'vllm.model_executor.models.gemma3_mm', 'vllm.model_executor.models.interfaces', 'vllm.model_executor.models.interfaces_base', 'vllm.model_executor.models.llama_eagle', 'vllm.model_executor.models.llama_eagle3', 'vllm.model_executor.models.mllama', 'vllm.model_executor.models.olmoe', 'vllm.model_executor.models.paligemma', 'vllm.model_executor.models.phi3v', 'vllm.model_executor.models.qwen2', 'vllm.model_executor.models.qwen2_5_vl', 'vllm.model_executor.models.qwen2_moe', 'vllm.model_executor.models.qwen2_vl', 'vllm.model_executor.models.qwen3', 'vllm.model_executor.models.qwen3_moe', 'vllm.model_executor.models.registry', 'vllm.model_executor.models.transformers', 'vllm.model_executor.models.utils', 'vllm.model_executor.models.vision', 'vllm.model_executor.models.whisper', 'vllm.model_executor.parameter', 'vllm.multimodal.hasher', 'vllm.multimodal.processing', 'vllm.multimodal.profiling', 'vllm.multimodal.registry', 'vllm.platforms', 'vllm.platforms.cpu', 'vllm.platforms.cuda', 'vllm.platforms.hpu', 'vllm.platforms.interface', 'vllm.platforms.neuron', 'vllm.platforms.rocm', 'vllm.platforms.tpu', 'vllm.platforms.xpu', 'vllm.plugins', 'vllm.prompt_adapter.models', 'vllm.prompt_adapter.worker_manager', 'vllm.reasoning.abs_reasoning_parsers', 'vllm.reasoning.deepseek_r1_reasoning_parser', 'vllm.reasoning.granite_reasoning_parser', 'vllm.sampling_params', 'vllm.scripts', 'vllm.spec_decode.draft_model_runner', 'vllm.spec_decode.smaller_tp_proposer_worker', 'vllm.spec_decode.spec_decode_worker', 'vllm.tracing', 'vllm.transformers_utils.config', 'vllm.transformers_utils.configs.arctic', 'vllm.transformers_utils.configs.dbrx', 'vllm.transformers_utils.configs.exaone', 'vllm.transformers_utils.configs.fm9g', 'vllm.transformers_utils.configs.jais', 'vllm.transformers_utils.configs.nemotron', 'vllm.transformers_utils.configs.solar', 'vllm.transformers_utils.tokenizer', 'vllm.transformers_utils.tokenizers.cpm_9g', 'vllm.transformers_utils.tokenizers.mistral', 'vllm.transformers_utils.utils', 'vllm.triton_utils.custom_cache_manager', 'vllm.triton_utils.importing', 'vllm.utils', 'vllm.v1.attention.backends.flash_attn', 'vllm.v1.attention.backends.mla.common', 'vllm.v1.attention.backends.mla.flashmla', 'vllm.v1.attention.backends.mla.triton_mla', 'vllm.v1.attention.backends.triton_attn', 'vllm.v1.core.block_pool', 'vllm.v1.core.encoder_cache_manager', 'vllm.v1.core.kv_cache_manager', 'vllm.v1.core.kv_cache_utils', 'vllm.v1.core.sched.scheduler', 'vllm.v1.engine.async_llm', 'vllm.v1.engine.core', 'vllm.v1.engine.core_client', 'vllm.v1.engine.detokenizer', 'vllm.v1.engine.llm_engine', 'vllm.v1.engine.logprobs', 'vllm.v1.executor.multiproc_executor', 'vllm.v1.kv_cache_interface', 'vllm.v1.metrics.loggers', 'vllm.v1.sample.ops.topk_topp_sampler', 'vllm.v1.sample.rejection_sampler', 'vllm.v1.spec_decode.eagle', 'vllm.v1.spec_decode.metrics', 'vllm.v1.structured_output', 'vllm.v1.structured_output.backend_guidance', 'vllm.v1.structured_output.backend_xgrammar', 'vllm.v1.utils', 'vllm.v1.worker.block_table', 'vllm.v1.worker.gpu_model_runner', 'vllm.v1.worker.gpu_worker', 'vllm.v1.worker.lora_model_runner_mixin', 'vllm.v1.worker.worker_base', 'vllm.worker.cache_engine', 'vllm.worker.cpu_model_runner', 'vllm.worker.cpu_worker', 'vllm.worker.enc_dec_model_runner', 'vllm.worker.model_runner', 'vllm.worker.model_runner_base', 'vllm.worker.multi_step_model_runner', 'vllm.worker.pooling_model_runner', 'vllm.worker.worker', 'vllm.worker.worker_base', 'vllm.worker.xpu_model_runner']
METHODS_WITH_REQUEST_ID = ['vllm.core.scheduler.Scheduler:abort_seq_group', 'vllm.core.scheduler.SchedulingBudget:add_num_batched_tokens', 'vllm.core.scheduler.SchedulingBudget:add_num_seqs', 'vllm.core.scheduler.SchedulingBudget:subtract_num_batched_tokens', 'vllm.core.scheduler.SchedulingBudget:subtract_num_seqs', 'vllm.engine.async_llm_engine.AsyncLLMEngine:_abort', 'vllm.engine.async_llm_engine.AsyncLLMEngine:abort', 'vllm.engine.async_llm_engine.AsyncLLMEngine:add_request', 'vllm.engine.async_llm_engine.AsyncLLMEngine:beam_search', 'vllm.engine.async_llm_engine.AsyncLLMEngine:encode', 'vllm.engine.async_llm_engine.AsyncLLMEngine:generate', 'vllm.engine.async_llm_engine.RequestTracker:abort_request', 'vllm.engine.async_llm_engine.RequestTracker:add_request', 'vllm.engine.async_llm_engine.RequestTracker:process_exception', 'vllm.engine.async_llm_engine.RequestTracker:propagate_exception', 'vllm.engine.async_llm_engine._AsyncLLMEngine:_abort_and_cache_schedule', 'vllm.engine.async_llm_engine._AsyncLLMEngine:_add_processed_request', 'vllm.engine.async_llm_engine._AsyncLLMEngine:_create_sequence_group_with_pooling', 'vllm.engine.async_llm_engine._AsyncLLMEngine:_create_sequence_group_with_sampling', 'vllm.engine.async_llm_engine._AsyncLLMEngine:_process_model_outputs', 'vllm.engine.async_llm_engine._AsyncLLMEngine:abort_request', 'vllm.engine.async_llm_engine._AsyncLLMEngine:add_request', 'vllm.engine.async_llm_engine._AsyncLLMEngine:add_request_async', 'vllm.engine.llm_engine.LLMEngine:_abort_and_cache_schedule', 'vllm.engine.llm_engine.LLMEngine:_add_processed_request', 'vllm.engine.llm_engine.LLMEngine:_create_sequence_group_with_pooling', 'vllm.engine.llm_engine.LLMEngine:_create_sequence_group_with_sampling', 'vllm.engine.llm_engine.LLMEngine:_process_model_outputs', 'vllm.engine.llm_engine.LLMEngine:abort_request', 'vllm.engine.llm_engine.LLMEngine:add_request', 'vllm.engine.multiprocessing.client.MQLLMEngineClient:_process_request', 'vllm.engine.multiprocessing.client.MQLLMEngineClient:abort', 'vllm.engine.multiprocessing.client.MQLLMEngineClient:beam_search', 'vllm.engine.multiprocessing.client.MQLLMEngineClient:encode', 'vllm.engine.multiprocessing.client.MQLLMEngineClient:generate', 'vllm.engine.protocol.EngineClient:abort', 'vllm.engine.protocol.EngineClient:beam_search', 'vllm.engine.protocol.EngineClient:encode', 'vllm.engine.protocol.EngineClient:generate', 'vllm.entrypoints.logger.RequestLogger:log_inputs', 'vllm.entrypoints.openai.serving_chat.OpenAIServingChat:_log_inputs', 'vllm.entrypoints.openai.serving_chat.OpenAIServingChat:chat_completion_full_generator', 'vllm.entrypoints.openai.serving_chat.OpenAIServingChat:chat_completion_stream_generator', 'vllm.entrypoints.openai.serving_completion.OpenAIServingCompletion:_log_inputs', 'vllm.entrypoints.openai.serving_completion.OpenAIServingCompletion:completion_stream_generator', 'vllm.entrypoints.openai.serving_completion.OpenAIServingCompletion:request_output_to_completion_response', 'vllm.entrypoints.openai.serving_embedding.OpenAIServingEmbedding:_log_inputs', 'vllm.entrypoints.openai.serving_embedding.OpenAIServingEmbedding:request_output_to_embedding_response', 'vllm.entrypoints.openai.serving_engine.OpenAIServing:_log_inputs', 'vllm.entrypoints.openai.serving_pooling.OpenAIServingPooling:_log_inputs', 'vllm.entrypoints.openai.serving_pooling.OpenAIServingPooling:request_output_to_pooling_response', 'vllm.entrypoints.openai.serving_score.ServingScores:_cross_encoding_score', 'vllm.entrypoints.openai.serving_score.ServingScores:_embedding_score', 'vllm.entrypoints.openai.serving_score.ServingScores:_log_inputs', 'vllm.entrypoints.openai.serving_score.ServingScores:_run_scoring', 'vllm.entrypoints.openai.serving_score.ServingScores:request_output_to_rerank_response', 'vllm.entrypoints.openai.serving_score.ServingScores:request_output_to_score_response', 'vllm.entrypoints.openai.serving_tokenization.OpenAIServingTokenization:_log_inputs', 'vllm.entrypoints.openai.serving_transcription.OpenAIServingTranscription:_log_inputs', 'vllm.entrypoints.openai.serving_transcription.OpenAIServingTranscription:transcription_stream_generator', 'vllm.sequence.ParallelSampleSequenceGroup:add_request', 'vllm.sequence.SequenceGroupBase:add_request', 'vllm.v1.engine.async_llm.AsyncLLM:abort', 'vllm.v1.engine.async_llm.AsyncLLM:add_request', 'vllm.v1.engine.async_llm.AsyncLLM:beam_search', 'vllm.v1.engine.async_llm.AsyncLLM:encode', 'vllm.v1.engine.async_llm.AsyncLLM:generate', 'vllm.v1.engine.llm_engine.LLMEngine:add_request', 'vllm.v1.engine.output_processor.RequestState:_new_request_output', 'vllm.v1.engine.processor.Processor:process_inputs', 'vllm.v1.metrics.stats.IterationStats:update_from_events', 'vllm.v1.metrics.stats.LoRARequestStates:preempted_request', 'vllm.v1.metrics.stats.LoRARequestStates:scheduled_request', 'vllm.v1.structured_output.backend_guidance.GuidanceGrammar:accept_tokens', 'vllm.v1.structured_output.backend_types.StructuredOutputGrammar:accept_tokens', 'vllm.v1.structured_output.backend_xgrammar.XgrammarGrammar:accept_tokens', 'vllm.v1.worker.gpu_input_batch.InputBatch:remove_request', 'vllm.worker.model_runner.ModelInputForGPUBuilder:InterDataForSeqGroup']
